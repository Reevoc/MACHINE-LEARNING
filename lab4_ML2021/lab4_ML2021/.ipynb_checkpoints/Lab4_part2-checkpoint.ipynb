{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Neural Networks: Regression on House Pricing Dataset\n",
    "We consider a reduced version of a dataset containing house sale prices for King County, which includes Seattle. It includes homes sold between May 2014 and May 2015.\n",
    "\n",
    "https://www.kaggle.com/harlfoxem/housesalesprediction\n",
    "\n",
    "For each house we know 18 house features (e.g., number of bedrooms, number of bathrooms, etc.) plus its price, that is what we would like to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 1 # COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Insert your ID number (\"numero di matricola\") below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#put here your ``numero di matricola''\n",
    "numero_di_matricola = 1 # COMPLETE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import all packages needed\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data, remove data samples/points with missing values (NaN) and take a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price</th>\n",
       "      <th>bedrooms</th>\n",
       "      <th>bathrooms</th>\n",
       "      <th>sqft_living</th>\n",
       "      <th>sqft_lot</th>\n",
       "      <th>floors</th>\n",
       "      <th>waterfront</th>\n",
       "      <th>view</th>\n",
       "      <th>condition</th>\n",
       "      <th>grade</th>\n",
       "      <th>sqft_above</th>\n",
       "      <th>sqft_basement</th>\n",
       "      <th>yr_built</th>\n",
       "      <th>yr_renovated</th>\n",
       "      <th>zipcode</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>sqft_living15</th>\n",
       "      <th>sqft_lot15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3.164000e+03</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "      <td>3164.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.645240e+09</td>\n",
       "      <td>5.354358e+05</td>\n",
       "      <td>3.381163</td>\n",
       "      <td>2.071903</td>\n",
       "      <td>2070.027813</td>\n",
       "      <td>1.525054e+04</td>\n",
       "      <td>1.434893</td>\n",
       "      <td>0.009798</td>\n",
       "      <td>0.244311</td>\n",
       "      <td>3.459229</td>\n",
       "      <td>7.615676</td>\n",
       "      <td>1761.252212</td>\n",
       "      <td>308.775601</td>\n",
       "      <td>1967.489254</td>\n",
       "      <td>94.668774</td>\n",
       "      <td>98077.125158</td>\n",
       "      <td>47.557868</td>\n",
       "      <td>-122.212337</td>\n",
       "      <td>1982.544564</td>\n",
       "      <td>13176.302465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.854203e+09</td>\n",
       "      <td>3.809004e+05</td>\n",
       "      <td>0.895472</td>\n",
       "      <td>0.768212</td>\n",
       "      <td>920.251879</td>\n",
       "      <td>4.254457e+04</td>\n",
       "      <td>0.507792</td>\n",
       "      <td>0.098513</td>\n",
       "      <td>0.776298</td>\n",
       "      <td>0.682592</td>\n",
       "      <td>1.166324</td>\n",
       "      <td>815.934864</td>\n",
       "      <td>458.977904</td>\n",
       "      <td>28.095275</td>\n",
       "      <td>424.439427</td>\n",
       "      <td>54.172937</td>\n",
       "      <td>0.140789</td>\n",
       "      <td>0.139577</td>\n",
       "      <td>686.256670</td>\n",
       "      <td>25413.180755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000102e+06</td>\n",
       "      <td>7.500000e+04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>6.490000e+02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>380.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1900.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98001.000000</td>\n",
       "      <td>47.177500</td>\n",
       "      <td>-122.514000</td>\n",
       "      <td>620.000000</td>\n",
       "      <td>660.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.199775e+09</td>\n",
       "      <td>3.150000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>1430.000000</td>\n",
       "      <td>5.453750e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1190.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1950.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98032.000000</td>\n",
       "      <td>47.459575</td>\n",
       "      <td>-122.324250</td>\n",
       "      <td>1480.000000</td>\n",
       "      <td>5429.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.027701e+09</td>\n",
       "      <td>4.450000e+05</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1910.000000</td>\n",
       "      <td>8.000000e+03</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>1545.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1969.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98059.000000</td>\n",
       "      <td>47.572500</td>\n",
       "      <td>-122.226000</td>\n",
       "      <td>1830.000000</td>\n",
       "      <td>7873.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>7.358175e+09</td>\n",
       "      <td>6.402500e+05</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>2500.000000</td>\n",
       "      <td>1.122250e+04</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>2150.000000</td>\n",
       "      <td>600.000000</td>\n",
       "      <td>1990.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>98117.000000</td>\n",
       "      <td>47.680250</td>\n",
       "      <td>-122.124000</td>\n",
       "      <td>2360.000000</td>\n",
       "      <td>10408.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>9.839301e+09</td>\n",
       "      <td>5.350000e+06</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>8010.000000</td>\n",
       "      <td>1.651359e+06</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6720.000000</td>\n",
       "      <td>2620.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>2015.000000</td>\n",
       "      <td>98199.000000</td>\n",
       "      <td>47.777600</td>\n",
       "      <td>-121.315000</td>\n",
       "      <td>5790.000000</td>\n",
       "      <td>425581.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id         price     bedrooms    bathrooms  sqft_living  \\\n",
       "count  3.164000e+03  3.164000e+03  3164.000000  3164.000000  3164.000000   \n",
       "mean   4.645240e+09  5.354358e+05     3.381163     2.071903  2070.027813   \n",
       "std    2.854203e+09  3.809004e+05     0.895472     0.768212   920.251879   \n",
       "min    1.000102e+06  7.500000e+04     0.000000     0.000000   380.000000   \n",
       "25%    2.199775e+09  3.150000e+05     3.000000     1.500000  1430.000000   \n",
       "50%    4.027701e+09  4.450000e+05     3.000000     2.000000  1910.000000   \n",
       "75%    7.358175e+09  6.402500e+05     4.000000     2.500000  2500.000000   \n",
       "max    9.839301e+09  5.350000e+06     8.000000     6.000000  8010.000000   \n",
       "\n",
       "           sqft_lot       floors   waterfront         view    condition  \\\n",
       "count  3.164000e+03  3164.000000  3164.000000  3164.000000  3164.000000   \n",
       "mean   1.525054e+04     1.434893     0.009798     0.244311     3.459229   \n",
       "std    4.254457e+04     0.507792     0.098513     0.776298     0.682592   \n",
       "min    6.490000e+02     1.000000     0.000000     0.000000     1.000000   \n",
       "25%    5.453750e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "50%    8.000000e+03     1.000000     0.000000     0.000000     3.000000   \n",
       "75%    1.122250e+04     2.000000     0.000000     0.000000     4.000000   \n",
       "max    1.651359e+06     3.500000     1.000000     4.000000     5.000000   \n",
       "\n",
       "             grade   sqft_above  sqft_basement     yr_built  yr_renovated  \\\n",
       "count  3164.000000  3164.000000    3164.000000  3164.000000   3164.000000   \n",
       "mean      7.615676  1761.252212     308.775601  1967.489254     94.668774   \n",
       "std       1.166324   815.934864     458.977904    28.095275    424.439427   \n",
       "min       3.000000   380.000000       0.000000  1900.000000      0.000000   \n",
       "25%       7.000000  1190.000000       0.000000  1950.000000      0.000000   \n",
       "50%       7.000000  1545.000000       0.000000  1969.000000      0.000000   \n",
       "75%       8.000000  2150.000000     600.000000  1990.000000      0.000000   \n",
       "max      12.000000  6720.000000    2620.000000  2015.000000   2015.000000   \n",
       "\n",
       "            zipcode          lat         long  sqft_living15     sqft_lot15  \n",
       "count   3164.000000  3164.000000  3164.000000    3164.000000    3164.000000  \n",
       "mean   98077.125158    47.557868  -122.212337    1982.544564   13176.302465  \n",
       "std       54.172937     0.140789     0.139577     686.256670   25413.180755  \n",
       "min    98001.000000    47.177500  -122.514000     620.000000     660.000000  \n",
       "25%    98032.000000    47.459575  -122.324250    1480.000000    5429.500000  \n",
       "50%    98059.000000    47.572500  -122.226000    1830.000000    7873.000000  \n",
       "75%    98117.000000    47.680250  -122.124000    2360.000000   10408.250000  \n",
       "max    98199.000000    47.777600  -121.315000    5790.000000  425581.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load the data\n",
    "df = pd.read_csv('kc_house_data.csv', sep = ',')\n",
    "\n",
    "#remove the data samples with missing values (NaN)\n",
    "df = df.dropna() \n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract input and output data. We want to predict the price by using features other than id as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data: 3164\n"
     ]
    }
   ],
   "source": [
    "Data = df.values\n",
    "# m = number of input samples\n",
    "m = Data.shape[0]\n",
    "print(\"Amount of data:\",m)\n",
    "Y = Data[:m,2]\n",
    "X = Data[:m,3:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Pre-Processing\n",
    "\n",
    "We split the data into 3 parts: one will be used for training and choosing the parameters, one for choosing among different models, and one for testing. The part for training and choosing the parameters will consist of $2/3$ of all samples, the one for choosing among different models will consist of $1/6$ of all samples, while the other part consists of the remaining $1/6$-th of all samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of data for training and deciding parameters: 2109\n",
      "Amount of data for validation (choosing among different models): 527\n",
      "Amount of data for test: 528\n"
     ]
    }
   ],
   "source": [
    "# Split data into train (2/3 of samples), validation (1/6 of samples), and test data (the rest)\n",
    "m_train = int(2./3.*m)\n",
    "m_val = int((m-m_train)/2.)\n",
    "m_test = m - m_train - m_val\n",
    "print(\"Amount of data for training and deciding parameters:\",m_train)\n",
    "print(\"Amount of data for validation (choosing among different models):\",m_val)\n",
    "print(\"Amount of data for test:\",m_test)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "Xtrain_and_val, Xtest, Ytrain_and_val, Ytest = train_test_split(X, Y, test_size=m_test/m, random_state=numero_di_matricola)\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(Xtrain_and_val, Ytrain_and_val, test_size=m_val/(m_train+m_val), random_state=numero_di_matricola)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's standardize the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data pre-processing\n",
    "from sklearn import preprocessing\n",
    "scaler = preprocessing.StandardScaler().fit(Xtrain)\n",
    "Xtrain_scaled = scaler.transform(Xtrain)\n",
    "Xtrain_and_val_scaled = scaler.transform(Xtrain_and_val)\n",
    "Xval_scaled = scaler.transform(Xval)\n",
    "Xtest_scaled = scaler.transform(Xtest)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "Let's start by learning a simple neural network with 1 hidden node.\n",
    "Note: we are going to use the input parameter solver='lbfgs' and random_state=numero_di_matricola to fix the random seed (so results are reproducible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.26394829987792656\n",
      "Error on validation data:  0.30404685789529706\n",
      "[array([[-214.80765928],\n",
      "       [ 268.96290924],\n",
      "       [ 524.01594613],\n",
      "       [ -60.62313943],\n",
      "       [   3.61781653],\n",
      "       [ 710.6640988 ],\n",
      "       [ 294.47836947],\n",
      "       [ 136.57678243],\n",
      "       [ 814.68281475],\n",
      "       [ 493.62511909],\n",
      "       [ 163.29062437],\n",
      "       [-581.29588365],\n",
      "       [  38.20577038],\n",
      "       [-203.4301266 ],\n",
      "       [ 600.22940461],\n",
      "       [-142.14771626],\n",
      "       [ 147.44059903],\n",
      "       [ -27.19275149]]), array([[141.16560883]])]\n",
      "[array([3793.50667568]), array([-48.05906964])]\n"
     ]
    }
   ],
   "source": [
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (1,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks vs Linear Models\n",
    "\n",
    "Let's learn a linear model on the other same data and compare the results with the simple NN above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.2653594216072852\n",
      "Error on validation data:  0.3115400506517969\n",
      "[-31303.71909156  35848.45081517  74506.78099995  -8012.41104949\n",
      "    671.23713588 100205.53195594  41671.19028923  19507.84532115\n",
      " 111331.50566184  69959.22677526  23468.73219785 -78236.93092911\n",
      "   6535.34729956 -28197.21476235  83701.76486765 -21647.26671149\n",
      "  22056.22833416  -2002.69401407]\n",
      "536831.9203413766\n"
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "\n",
    "LR = linear_model.LinearRegression()\n",
    "\n",
    "#fit the model on training data\n",
    "LR.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - LR.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - LR.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(LR.coef_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(LR.intercept_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is there a way to make a NN network learn a linear model?\n",
    "\n",
    "Let's first check what is the loss used by MLPRegressor..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.26535942166590454\n",
      "Error on validation data:  0.31153906582827584\n",
      "[array([[  51.55070235],\n",
      "       [ -59.02846704],\n",
      "       [-122.96939596],\n",
      "       [  13.19466306],\n",
      "       [  -1.10694448],\n",
      "       [-165.016906  ],\n",
      "       [ -68.62491747],\n",
      "       [ -32.12596414],\n",
      "       [-183.34020234],\n",
      "       [-114.96558392],\n",
      "       [ -38.51551396],\n",
      "       [ 128.83877577],\n",
      "       [ -10.76237595],\n",
      "       [  46.43749972],\n",
      "       [-137.83874569],\n",
      "       [  35.64844107],\n",
      "       [ -36.32214078],\n",
      "       [   3.29740834]]), array([[-607.24280969]])]\n",
      "[array([-883.44724722]), array([365.29153421])]\n"
     ]
    }
   ],
   "source": [
    "#let's write the code to learn a linear model with NN: how? \n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (1,), solver = \"lbfgs\", random_state = numero_di_matricola, activation = \"identity\")\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that there is an $\\ell_2$ regularization term in MLPRegressor. What about making it smaller?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More Complex NNs\n",
    "\n",
    "Let's try more complex NN, for example increasing the number of nodes in the only hidden layer, or increasing the number of hidden layers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 2 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.18062109487942002\n",
      "Error on validation data:  0.2071985800968661\n",
      "[array([[  90.99941381,  -33.31779023],\n",
      "       [ 120.42499648,   39.32679895],\n",
      "       [  85.74353857,   73.03492528],\n",
      "       [-261.23164773,   28.27522451],\n",
      "       [ -30.58416588,   17.89847762],\n",
      "       [ 198.14343088,   25.46992154],\n",
      "       [  34.88372182,   37.57366671],\n",
      "       [  96.94676979,   25.69592196],\n",
      "       [ 312.39515229,  132.8764007 ],\n",
      "       [  85.00238164,   68.82140272],\n",
      "       [  19.25029521,   23.37631945],\n",
      "       [-217.42668935,  -81.21134469],\n",
      "       [  -3.51203035,   20.11174383],\n",
      "       [-301.19459787,  -26.38167448],\n",
      "       [ 305.52080917,  144.59932976],\n",
      "       [-463.75030123,  -16.40475018],\n",
      "       [ 194.5398277 ,   52.91459507],\n",
      "       [-250.87012025,  -11.15825198]]), array([[614.56980061],\n",
      "       [548.8458984 ]])]\n",
      "[array([-1049.61719913,   897.58810555]), array([725.96792918])]\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 nodes in the only hidden layer\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (2,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 5 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.16260879498841674\n",
      "Error on validation data:  0.2145202694399876\n",
      "[array([[ -168.09486982,   143.47517422,    94.01034403,   172.70732352,\n",
      "          -55.64719254],\n",
      "       [  298.94903373,   397.23600398,   225.43643321,   134.16188775,\n",
      "           -4.74482326],\n",
      "       [ -380.96028133,   333.78677087,   227.73462878,  -306.05084185,\n",
      "          287.55866552],\n",
      "       [ -160.87033474,   -24.42821603,  -750.80921338,    97.3368281 ,\n",
      "           74.59941455],\n",
      "       [  831.28279715,  -913.77714326,   148.8889618 ,   -35.25938417,\n",
      "          -95.68376385],\n",
      "       [ -379.34965485,   682.70626308,   537.79964382,  -509.32700206,\n",
      "          -90.85272994],\n",
      "       [ -590.90249629,   663.71024863,   -18.46692083,  -455.20630629,\n",
      "          203.75629121],\n",
      "       [   96.51283147,   765.83586851,   168.74040587,   -44.97937112,\n",
      "           33.98481024],\n",
      "       [ -399.51068088,   684.1429114 ,   614.97455191,    77.34360098,\n",
      "          426.63939177],\n",
      "       [ -488.60649903,   574.35847278,   267.19825492,  -160.14197266,\n",
      "          239.23319094],\n",
      "       [  117.16958031,  -367.93315682,   -25.19197163,  -328.74343779,\n",
      "          146.71482421],\n",
      "       [  573.14963567,  -298.92818854,  -402.5508182 ,  -292.73558341,\n",
      "         -310.89822649],\n",
      "       [   -1.94735134,   981.61916225,  -429.17900493,  -622.59828048,\n",
      "           40.39900102],\n",
      "       [  354.36993664, -1341.80052851,  -527.60236003,  -175.20664274,\n",
      "         -101.69938622],\n",
      "       [ -447.85688525,   431.09184979,   790.47571061,   -22.85719515,\n",
      "          489.72489183],\n",
      "       [ -138.01656313,   815.25542256, -1244.85800101,   447.62458048,\n",
      "         -218.74720416],\n",
      "       [  438.91601916,   259.69155531,   386.70885825,     8.5753112 ,\n",
      "           98.56328027],\n",
      "       [   79.35359751,  -197.74251677,  -699.98014468,   255.40773035,\n",
      "         -153.36713724]]), array([[ 55.6905778 ],\n",
      "       [ 44.18209152],\n",
      "       [264.54349185],\n",
      "       [ 78.9448327 ],\n",
      "       [218.28551113]])]\n",
      "[array([ 1953.2191243 , -1114.63395175, -2823.20827903,   227.54777591,\n",
      "        1411.16229018]), array([395.99163238])]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 5 nodes in the only hidden layer\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (5,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that with a smaller number of iterations we had a larger error on training set but a smaller error on validation data -> \"early stopping is a form of regularization\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 10 nodes in the only hidden layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.1226812203980927\n",
      "Error on validation data:  0.3028737849736476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 10 nodes in the only hidden layer\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (10,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "#print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "#print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's build a NN with 100 nodes in the only hidden layer. Note that this is the default!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.031779439320063885\n",
      "Error on validation data:  0.5431090816679929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 100 nodes in the only hidden layer\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (100,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "#print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "#print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 1 node each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.23811125681551426\n",
      "Error on validation data:  0.273027867947361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 hidden layers, 1 node each\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (1, 1,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "#print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "#print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 2 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error on training data:  0.21289957649687308\n",
      "Error on validation data:  0.2692207014633645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Giovanni\\anaconda3\\lib\\site-packages\\sklearn\\neural_network\\_multilayer_perceptron.py:500: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  self.n_iter_ = _check_optimize_result(\"lbfgs\", opt_res, self.max_iter)\n"
     ]
    }
   ],
   "source": [
    "#let's build a NN with 2 layers, 2 nodes each\n",
    "\n",
    "#let's load the MLPRegressor\n",
    "\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "#let's define the model\n",
    "\n",
    "NN = MLPRegressor(hidden_layer_sizes = (2, 2,), solver = \"lbfgs\", random_state = numero_di_matricola)\n",
    "\n",
    "#let's learn the model on training data\n",
    "NN.fit(Xtrain_scaled, Ytrain)\n",
    "\n",
    "#let's print the error (1 - R^2) on training data\n",
    "print(\"Error on training data: \", 1 - NN.score(Xtrain_scaled, Ytrain))\n",
    "\n",
    "#let's print the error (1 - R^2) on validation data\n",
    "print(\"Error on validation data: \", 1 - NN.score(Xval_scaled, Yval))\n",
    "\n",
    "#let's print the coefficients of the model for the input nodes (but not the bias)\n",
    "#print(NN.coefs_)\n",
    "\n",
    "#let's print the coefficient for the bias (i.e., the bias)\n",
    "#print(NN.intercepts_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 10 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's build a NN with 2 layers, 10 nodes each\n",
    "\n",
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try 2 layers, 100 nodes each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's build a NN with 2 layers, 100 nodes each\n",
    "\n",
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So it seems that 1 layer (and default number of iterations) works best for this dataset. Let's try 5-fold cross-validation with number of nodes in the hidden layer between 1 and 20.\n",
    "Note that we use train and validation data together, since we are doing cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's check what is the best parameter, and compare the best NNs with the linear model (learned on train and validation) on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's print the best model according to grid search\n",
    "#COMPLETE\n",
    "\n",
    "#let's print the error 1-R^2 for the best model\n",
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let compare the error of the best NN on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's learn the linear model on train and validation, and get error (1-R^2) on train and validation and on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#COMPLETE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note: MLPRegressor has several other parameters!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
